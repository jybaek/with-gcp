앞에서 *CloudML* 에 대한 이야기를 많이 했는데 사실 일반 *VM instance (Compute Engine)* 로 머신러닝을 이용하는 것에 비해 무엇이 좋은지 자세히 다루지 않았다. 이번 글을 통해 몇 가지 장점을 살펴보도록 하자.

## 비용

아마도 가장 큰 장점이 되겠다. 다른 작업은 몰라도 머신러닝/딥러닝은 고사양 시스템을 필요로 하며 프로젝트에 따라 훈련시간이 굉장히 오래걸리기도 한다. *GCE* 는 사용하지 않을 때 중지하는 것이 비용을 절약할 수 있는 방법인데 딥러닝 *training* 이  언제 끝날지 알 수 없기 때문에 인스턴스를 무작정 켜놓을 수밖에 없다. 고사양 시스템으로 설정된 인스턴스를, 그것도 GPU 가 장착된 머신이라면 가격은 생각보다 끔찍할 수 있다. 반면 *CloudML* 은 인스턴스 없이 *training job* 을 던지고 끝이니 가격면에서 훨씬 유리하다고 할 수 있겠다.

## 쿼타 

*GPU* 를 사용하기 위해서는 쿼타를 신청해야 하는데, 대략 "난 몇 개의 *GPU* 가 어떠한 목적으로 필요하다" 라고 간단한 메시지를 *Google Cloud* 팀에 보내게 된다. 신청이 *accept* 되면 그때부터 신청한 쿼타대로 *GPU* 를 사용할 수 있는데 여기서 다시 한번 *CloudML* 이 비용/시간적인 우위를 차지하게 된다. 무슨말이냐하면 *GCE* 의 경우에 GPU 1 개를 장착하고 *training* 하면 *GPU* 점유 문제로 다른 *training* 은 돌릴 수 없게 된다 (다른 *job* 을 돌리면 시스템 사양을 제대로 사용하지 못하기 때문에 시간이 곱절로 늘어나게 됨). 하지만 *CloudML* 은 *job* 별로 다른 *GPU* 가 설정되어 여러 *job* 을 돌리는데 무리가 없다. 

딥러닝을 조금 다뤄본 사용자라면 학습 과정에서 *hyperparameters* 수정 때문에 여러번 *training* 을 해야 한다는 사실을 잘 알고 있을텐데 적당히 값을 바꿔가며 병렬로 *job* 을 던질 수 있다는 장점이 있다. 아래 사진을 통해 단일로 작업을 던진 `kaggle_1` 과 동시에 3개의 *job* 을 던졌을 때의 시간을 비교할 수 있다. 별 차이가 없이 병렬처리가 잘 수행되었다.

![](https://t1.daumcdn.net/cfile/tistory/99342B375A4DC81302)

※ 너무 많은 쿼타를 요구하게 되면 사용료를 지불 할 수 있는 충분한 자금이 있는지 등 검토하는 과정을 거치게되니 참고하도록 하자. 그리고 사용목적은 너무 상세히 작성할 필요가 없다. 내 경우에 `kaggle` 이라고만 써서 보내도 그냥 *accept* 되더라.

## 안정성

사실 이런 경우는 극히 드물텐데 *GCE* 가 먹통이 되는 경우 되겠다. 머신러닝을 위한 여러가지 셋업이 되어 있는 상태. 그리고 학습 데이터와 기타 등등의 파일들이 모두 저장되어 있는 인스턴스가 먹통이 되어 다시 만들어야 하는 경우가 발생한다면 썩 반가운 일은 아닐 것이다. 반면 *CloudML* 은 이런 문제가 없다. 

*GCE* 는 이런 경우를 대비해서 최소한 *input data* 와 *output* 을 *Google Cloud Storage (GCS)* 로 사용하는 것을 추천한다.

## 결론

머신러닝/딥러닝을 위해 서비스 되고 있는게 *CloudML* 이다. 사용하지 않을 이유가 있나?
